{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c167d6-2d43-420a-a8e3-964867672c44",
   "metadata": {},
   "source": [
    "# Resampling Methods (Introduction)\n",
    "* *Resampling methods* is an indispensable tool in modern statistics, involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model.\n",
    "* This approach may allow us to obtain information that would not be available from fitting the model only once using the original training sample.\n",
    "* Can be computationally expensive (involve fitting the same statistical method multiple times using different subsets of the training data).\n",
    "* Commonly used resampling methods - `Cross Validation` and `Bootstraping`.\n",
    "* ***Cross-validation*** can be used to estimate the test error associated with a given statistical learning method in order to evaluate its performance, or to select the appropriate level of flexibility :\n",
    "  * The process of evaluating a model’s performance is known as *model assessment*.\n",
    "  * The process of selecting the proper level of flexibility for a model is known as *model selection*.\n",
    "* On the other hand, ***bootstrap***is to provide a measure of accuracy of a parameter estimate or of a given statistical learning method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5853308-39ee-4ea2-ba67-3ba1c664a099",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "* The *test error* is the average error that results from using a statistical learning method to predict the response on a new observation - can be easily calculated if a designated test set is available - Unfortunately, it is not the case in reality -  computed as $$ test error = Avg(y_{0}- \\hat{f}(x_{0}))^2$$\n",
    "* The *training error* using the training data that was used to fit the model, and so should more accurately and it is computed as\n",
    "$$ MSE_{train}=\\frac{1}{n}\\cdot \\sum_{i=1}^{n}\\left(y_{i}-\\hat{f}(x_{i})\\right)^2 $$\n",
    "* We want to choose the method that gives the ***lowest test MSE***, as opposed to the *lowest training MSE*.\n",
    "* There is no guarantee that the method with the lowest training MSE will also have the lowest test MSE.\n",
    "* Goal is to find suitable means for calculating *test error* in the absence of a very large designated test set that can be used to directly estimate the test error rate!\n",
    "### The Validation Set Approach\n",
    "* It involves randomly dividing the available set of observations into two parts, a *training set* and a *validation set* a.k.a *hold-out set*.\n",
    "* Now, model is fit on the training set, and the fitted model is used to predict the responses for the observations in the validation set.\n",
    "* The resulting validation set error rate provides an estimate of the test error rate.\n",
    "* If we repeat the process of randomly splitting the sample set into two parts, we will get a somewhat different estimate for the test MSE.\n",
    "* The validation set approach is conceptually simple and is easy to implement.\n",
    "* Drawbacks of Validation Set Approach -\n",
    "  * The validation estimate of the test error rate can be highly variable, depending upon precisely which observations are included in the training set and validation sets respectively.\n",
    "  * Since, only a subset of the observations are made as training set and validation sets, as per statistical methods tend to perform worse when trained on fewer observations, validation set error rate may tend to **over-estimate** the test error rate for the model fit on the entire data set.\n",
    "### Leave-One-Out Cross-Validation (LOOCV)\n",
    "* LOOCV involves splitting the set of observations into two parts - a single observation (x1, y1) is used for the validation set, and the remaining observations {(x2, y2), . . . , (xn, yn)} make up the training set.\n",
    "* The statistical learning method is fit on the n − 1 training observations, and a prediction is made for the excluded observation, using its value x1.\n",
    "* MSE will be calculated as MSE = (y1-ŷ)^2. But even though MSE1 is unbiased for the test error, it is a poor estimate because it is highly variable, since it is based upon a single observation (x1, y1).\n",
    "* Repeating this approach *n* times produces *n* squared errors,\n",
    "  $$CV_{(n)} = \\frac{1}{n}\\cdot \\sum_{i=1}^{n} MSE_{i}$$.\n",
    "* LOOCV has the potential to be expensive to implement, since the model has to be fit *n* times.\n",
    "* But an amazing shortcut makes the cost of LOOCV the same as that of a single model fit! The following formula holds:\n",
    "$$CV_{(n)} = \\frac{1}{n}\\cdot \\sum_{i=1}^{n}\\left(\\frac{y_{i}-\\hat{y}}{1-h_{i}}\\right)^2$$.\n",
    "\n",
    "### k-Fold Cross-Validation\n",
    "* Alternative to LOOCV.\n",
    "* This approach involves randomly dividing the set of observations into *k* groups, or *folds*, of approximately equal size.\n",
    "* The first fold is treated as a validation set, and the method is fit on the remaining k − 1 folds.\n",
    "* The mean squared error, MSE1, is then computed on the observations in the *held-out* fold.\n",
    "* This procedure is repeated *k* times; each time, a different group of observations is treated as a validation set.\n",
    "* This process results in k estimates of the test error, k-fold CV estimate is computed.\n",
    "* LOOCV is a special case of k-fold CV in which k is set to equal n (In practice k=5 or k=10 is performed).\n",
    "* When we perform cross-validation, our goal might be to determine how well a given statistical learning procedure can be expected to perform on independent data - the actual estimate of the *test MSE*.\n",
    "* But at other times, ***location of the minimum point in the estimated test MSE curve*** - we might be performing cross-validation on a number of statistical learning methods, or on a single method using different levels of flexibility, in order to identify the method that results in the lowest test error.\n",
    "* An important advantage of k-fold CV - it often gives more accurate estimates of the test error rate than does LOOCV.\n",
    "* From the perspective of bias reduction, it is clear that LOOCV is to be preferred to k-fold CV. ***Note***: LOOCV will give approximately unbiased estimates of the test error, since each training set contains n−1 observations and performing k-fold CV for, say, k = 5 or k = 10 will lead to an intermediate level of bias.\n",
    "* But variance perspective also needs to taken into consideration! LOOCV has higher variance than does k-fold CV with k < n. When we perform LOOCV, we are in effect averaging the outputs of n fitted models, each of which is trained on an almost identical set of observations; therefore, these outputs are highly (positively) correlated\n",
    "with each other. When we perform k-fold CV with k < n, we are averaging the outputs of k fitted models that are somewhat less correlated with each other, since the overlap between the training sets in each model is smaller.\n",
    "* The test error estimate resulting from LOOCV tends to have higher variance than does the test error estimate resulting from k-fold CV.\n",
    "* To summarize, there is a bias-variance trade-off associated with the choice of k in k-fold cross-validation.\n",
    " $$CV_{(k)} = \\frac{1}{k}\\cdot \\sum_{i=1}^{k} MSE_{i}$$.\n",
    "### Cross-Validation on Classification Problems\n",
    "* Cross-validation can also be a very useful approach in the classification setting when Y is *qualitative*.\n",
    "* Rather than using MSE to quantify test error, we instead use the ***number of misclassified observations***.\n",
    "* the training error tends to ↓, as the flexibility of the fit ↑."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c3a05-fb3d-42b2-9b2f-88d24a939724",
   "metadata": {},
   "source": [
    "## Bootstrap\n",
    "* Widely applicable and extremely powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method.\n",
    "* The power of the bootstrap lies in the fact that it can be easily applied to a wide range of statistical learning methods, including some for which a measure of variability is otherwise difficult to obtain.\n",
    "* The bootstrap approach allows us to use a computer to emulate the process of obtaining new sample sets.\n",
    "* Rather than repeatedly obtaining independent data sets from the population, we instead obtain distinct data sets by repeatedly sampling observations from the original data set.\n",
    "* When the sampling is performed with replacement, which means that the same observation can occur more than once in the bootstrap data set, we call them ***sampling with replacement*** and vice-versa.\n",
    "<br>\n",
    "Let `Z`→ original data set with `n` observations.<br> We randomly take n observations from the data set in order to produce a bootstrap data set `Z*1`.<br> The sampling is performed ***with replacement*** and thus its estimate will be `^α1`.<br> Let `B` → no.of.times bootstrapped; for some large value of B. <br> Thus, corresponding `α`\n",
    "estimates, `ˆα1, ˆα2, . . . , ˆαB`. <br> Then the *estimate of the standard error of `^α` is given by: * $$ SE_{B}(\\hat{\\alpha}) = \\sqrt{\\frac{1}{B-1}\\cdot \\sum_{r=1}^{B}\\left(\\hat{\\alpha}^\\ast r-\\frac{1}{B}\\sum_{r'=1}^{B} \\hat{\\alpha}^\\ast r'\\right)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cae5bf-9c37-4b1d-9873-6e2928b0e3a6",
   "metadata": {},
   "source": [
    "# Lab Codes: Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc83656-cb81-4e11-8365-c04919480c17",
   "metadata": {},
   "source": [
    "## Step 1:Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45caac01-6e53-41ad-8983-766ccaaec3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "summarize ,\n",
    "poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58fc605-b11a-477d-a7db-f74e5c6bbb81",
   "metadata": {},
   "source": [
    "## Step 2: Neccesary modules import for CV and Bootstrappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfb4f0b-1630-49d1-b385-35b9a6b1bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "(cross_validate ,\n",
    "KFold ,\n",
    "ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec346d-16bc-4459-b061-d7cd6cc15aad",
   "metadata": {},
   "source": [
    "## Step 3A:  The Validation Set Approach\n",
    "* We explore the use of the *validation set approach* in order to estimate the test error rates that result from fitting various linear models on the `Auto` data set.\n",
    "* We use the function `train_test_split()` to split the data into training and validation sets.\n",
    "* As there are 392 observations, we split into two equal sets of size 196 using the argument `test_size=196`.\n",
    "* It is generally a good idea to set a *random seed* when performing operations like this that contain an element of randomness, so that the results obtained can be reproduced precisely at a later time.\n",
    "* We set the random seed of the splitter with the argument `random_state=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f1f7f88-812d-4c84-b9f7-a1dade8b5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train , Auto_valid = train_test_split(Auto ,\n",
    "                                           test_size=196,\n",
    "                                           random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae5dfb-7a13-4092-9d37-8403bc044b8f",
   "metadata": {},
   "source": [
    "Now we can fit a *linear regression* using only the observations corresponding to the training set `Auto_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60750bb1-f290-4afe-8d25-b002b5f987d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train , X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144cdbd-94b2-4854-a7e3-5fc11769f8fa",
   "metadata": {},
   "source": [
    "We now use the `predict()` method of `results` evaluated on the model matrix for this model created using the validation data set. We also calculate the validation MSE of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8730f3af-75b4-4840-99c8-351e95bb062b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(23.61661706966988)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c3fc8-904c-4539-bea1-3d20fcc666c8",
   "metadata": {},
   "source": [
    "Hence our estimate for the validation MSE of the linear regression fit is 23.62.<br>\n",
    "We can also estimate the validation error for higher-degree polynomial regressions. \n",
    "We first provide a function `evalMSE()` that takes a model string as well as a training and test set and returns the MSE on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f791b39a-dfc6-40ad-a85e-5ec618187bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms ,response ,train ,test):\n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "    results = sm.OLS(y_train , X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "    return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506f689-86be-410b-b2dc-7b8e226610e4",
   "metadata": {},
   "source": [
    "Let’s use this function to estimate the validation MSE using linear, quadratic and cubic fits. <br>We use the `enumerate()` function here, which gives both the values and indices of objects as one iterates over a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0225f8-054a-46cd-a3be-9076e92773e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "for idx , degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],'mpg',Auto_train ,Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbce80a-71da-4f73-85fd-8642d15f583f",
   "metadata": {},
   "source": [
    "These error rates are 23.62, 18.76, and 18.80, respectively. If we choose a different training/validation split instead, then we can expect somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c006c1e-93ef-4cbb-ab84-4bcb6823ee7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train , Auto_valid = train_test_split(Auto , test_size=196, random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "for idx , degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],'mpg',Auto_train ,Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac5c122-56a1-4fde-997c-980b8c5ddc05",
   "metadata": {},
   "source": [
    "Using this split of the observations into a training set and a validation set, we find that the validation set error rates for the models with linear, quadratic, and cubic terms are 20.76, 16.95, and 16.97, respectively.<br>\n",
    "These results are consistent with our previous findings: a model that predicts mpg using a quadratic function of `horsepower` performs better than a model that involves only a linear function of `horsepower`, and there is no evidence of an improvement in using a cubic function of `horsepower`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d36b90-bd6e-4e73-ac90-bae75f7665eb",
   "metadata": {},
   "source": [
    "## Step 3B: Cross-Validation\n",
    "* In theory, the cross-validation estimate can be computed for any generalized linear model.\n",
    "* In practice, however, the simplest way to cross-validate in Python is to use `sklearn`, which has a different interface or API than `statsmodels`, the code we have been using to fit GLMs.\n",
    "* This is a problem which often confronts data scientists: “*I have a function to do task A, and need to feed it into something that performs task B, so that I can compute B(A(D)), where D is my data.*” When A and B don’t naturally speak to each other, this requires the use of a **wrapper**.\n",
    "* In the `ISLP` pacakage, we provide a wrapper, `sklearn_sm()`, that enables us to easily use the cross-validation tools of `sklearn` with models fit by `statsmodels`.\n",
    "* The class `sklearn_sm()` has as its first argument a model from `statsmodels`.\n",
    "* It can take two additional optional arguments: `model_str` which can be used to specify a formula, and `model_args` which should be a dictionary of additional arguments used when fitting the model.\n",
    "* For example, to fit a logistic regression model we have to specify a `family` argument.\n",
    "* This is passed as `model_args={'family':sm.families.Binomial()}`.\n",
    "* Here is our wrapper in action -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7da2f5-2880-48f8-90d8-8373d60520d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(24.231513517929216)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = sklearn_sm(sm.OLS ,\n",
    "                      MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model ,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd503a-7119-4868-b5d2-d572c9d2bc92",
   "metadata": {},
   "source": [
    "1. The arguments to `cross_validate()` are as follows:\n",
    "   * An object with the appropriate `fit()`, `predict()`, and `score()` methods, an array of features X and a response Y.\n",
    "2. We also included an additional argument `cv` to `cross_validate()`; specifying an integer `K` results in *K-fold cross-validation*.\n",
    "3. We have provided a value corresponding to the total number of observations, which results in *leave-one-out cross-validation (LOOCV)*.\n",
    "4. The `cross_validate()` function produces a dictionary with several components; we simply want the cross validated test score here (MSE), which is estimated to be 24.23.<br>\n",
    "* We can repeat this procedure for increasingly complex polynomial fits.\n",
    "* To automate the process, we again use a `for` loop which iteratively fits polynomial regressions of degree 1 to 5, computes the associated crossvalidation error, and stores it in the ith element of the vector `cv_error`.\n",
    "* The variable `d` in the `for` loop corresponds to the degree of the polynomial.\n",
    "* We begin by initializing the vector.\n",
    "* This command may take a couple of seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc41d89b-5f18-4b80-a0f2-24a755ef201a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443031, 19.03320903])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd88aa4-63bb-4b64-931c-8fd7754e709a",
   "metadata": {},
   "source": [
    "We see a sharp drop in the estimated test MSE between the linear and quadratic fits, but then no clear improvement from using higher-degree polynomials.<br>\n",
    "* Above we introduced the `outer()` method of the `np.power()` function.\n",
    "* The `outer()` method is applied to an operation that has two arguments, such as `add()`, `min()`, or `power()`.\n",
    "* It has two arrays as arguments, and then forms a larger array where the operation is applied to each pair of elements of the two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "727f68c6-1260-475b-bc4c-b7522163fdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [11, 13]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470c73f-c6dc-44c1-b5d0-40b3afe69782",
   "metadata": {},
   "source": [
    "* In the CV example above, we used `K = n`, but of course we can also use `K < n`.\n",
    "* The code is very similar to the above (and is significantly faster).\n",
    "* Here we use `KFold()` to partition the data into `K = 10` random groups.\n",
    "* We use random_state to set a random seed and initialize a vector `cv_error` in which we will store the CV errors corresponding to the polynomial fits of degrees one to five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a45ed2f-8906-4bfb-a9a3-878880641acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848402, 19.13722633])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,shuffle=True ,random_state=0) # use same splits for each degree\n",
    "\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9b7d7-0de1-4856-a4d5-41edd7fed304",
   "metadata": {},
   "source": [
    "1. Notice that the computation time is much shorter than that of LOOCV.(In principle, the computation time for LOOCV for a least squares linear model should be faster than for K-fold CV, due to the availability of the\n",
    "formulafor LOOCV; however, the generic `cross_validate()` function does not make use of this formula.)\n",
    "2. We still see little evidence that using cubic or higher-degree polynomial terms leads to a lower test error than simply using a quadratic fit.\n",
    "3. The `cross_validate()` function is flexible and can take different splitting mechanisms as an argument.\n",
    "4. For instance, one can use the `ShuffleSplit()` funtion to implement the validation set approach just as easily as K-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fcd53bc-64aa-4720-8a2a-801e248964fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model ,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation);\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af17a90-e8b0-41d5-9d52-e3b7074b851c",
   "metadata": {},
   "source": [
    "One can estimate the variability in the test error by running the following-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82da3c41-6b6e-48b4-b7be-7347900a79d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(23.802232661034164), np.float64(1.4218450941091847))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model ,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d55c1-8f56-4c7d-b5b3-1cdb1f29cb3f",
   "metadata": {},
   "source": [
    "Note that this *standard deviation* is not a valid estimate of the sampling variability of the *mean* test score or the individual scores, since the randomly-selected training samples overlap and hence introduce correlations. But it does give an idea of the **Monte Carlo variation** incurred by picking different random folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11afed94-22b3-4b28-ac17-caf60ae469a9",
   "metadata": {},
   "source": [
    "## Step 3C: The Bootstrap\n",
    "### Estimating the Accuracy of a Statistic of Interest\n",
    "* One of the great advantages of the bootstrap approach is that it can be applied in almost all situations.\n",
    "* No complicated mathematical calculations are required.\n",
    "* While there are several implementations of the bootstrap in Python, its use for estimating standard error is simple enough that we write our own function below for the case when our data is stored in a dataframe.\n",
    "* To illustrate the bootstrap, we start with a simple example.\n",
    "* The `Portfolio` data set in the `ISLP` package is described in Section 5.2.\n",
    "* The goal is to estimate the sampling variance of the parameter ) given in formula (5.7).\n",
    "* We will create a function `alpha_func()`, which takes as input a dataframe `D` assumed to have columns `X` and `Y`, as well as a vector `idx` indicating which observations should be used to estimate `α`.\n",
    "* The function then outputs the estimate for `α` based on the selected observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc3370b-681a-42f3-8071-1c220ac4bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "    return ((cov_[1,1] - cov_[0,1]) /(cov_[0,0]+cov_[1,1]-2*cov_[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f8bdc-d27d-49fc-a7f9-dafbcbd9702b",
   "metadata": {},
   "source": [
    "This function returns an estimate for `α` based on applying the minimum variance formula to the observations indexed by the argument `idx`. For instance, the following command estimates `α` using all 100 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34c89eb7-1fa1-443d-9ef8-0609fde2f9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.57583207459283)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_func(Portfolio , range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1903dc0d-ccac-43fb-abcc-7d8843e8b5a1",
   "metadata": {},
   "source": [
    "Next we randomly select 100 observations from `range(100)`, with replacement. This is equivalent to constructing a new bootstrap data set and recomputing `ˆα` based on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a187284c-8947-4553-85cc-ac4fd39e40cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6074452469619004)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio ,\n",
    "           rng.choice(100,100,replace=True)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c3e46e-fe1c-46bd-992a-6f17e85c8f8a",
   "metadata": {},
   "source": [
    "This process can be generalized to create a simple function `boot_SE()` for computing the bootstrap standard error for arbitrary functions that take only a data frame as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c37e4786-a18c-45f8-bb73-cc120de74d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func, D, n=None, B=1000, seed=0, *args, **kwargs):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0 \n",
    "    n = n or D.shape[0]\n",
    "\n",
    "    for _ in range(B):\n",
    "        # Use integer positions instead of index labels\n",
    "        idx = rng.choice(len(D), n, replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "        \n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7abb6-6640-4aa5-bd25-4a100d167a5f",
   "metadata": {},
   "source": [
    "Notice the use of `_ `as a loop variable in `for _ in range(B)`. This is often used if the value of the counter is unimportant and simply makes sure the loop is executed `B` times.<br>Let’s use our function to evaluate the accuracy of our estimate of α using B = 1,000 bootstrap replications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a73d6e2a-9aaf-4675-8368-46f6d2cab76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.019199498387420112)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func ,\n",
    "                   Portfolio ,\n",
    "                   B=1000,\n",
    "                   seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a3bbf2-b1b2-4c16-a56e-7c309c75ab34",
   "metadata": {},
   "source": [
    "The final output shows that the bootstrap estimate for `SE(ˆα)` is 0.0912."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fea306-e0f5-44f0-8bca-420ebe1b0cd6",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Linear Regression Model\n",
    "* The bootstrap approach can be used to assess the variability of the coefficient estimates and predictions from a statistical learning method.\n",
    "* Here we use the bootstrap approach in order to assess the variability of the estimates for `β₀` and `β₁` the intercept and slope terms for the linear regression model that uses `horsepower` to predict `mpg` in the `Auto` data set.\n",
    "* We will compare the estimates obtained using the bootstrap to those obtained using the formulas for `SE(ˆβ₀)` and `SE(ˆβ₁)`.\n",
    "* To use our `boot_SE()` function, we must write a function (its first argument) that takes a data frame `D` and indices `idx` as its only arguments.\n",
    "* But here we want to bootstrap a specific regression model, specified by a model formula and data.\n",
    "* We show how to do this in a few simple steps.\n",
    "* We start by writing a generic function `boot_OLS()` for bootstrapping a regression model that takes a formula to define the corresponding regression.\n",
    "* We use the `clone()` function to make a copy of the formula that can be refit to the new dataframe.\n",
    "* This means that any derived features such as those defined by `poly()` (which we will see shortly), will be re-fit on the resampled data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96cf8453-2b97-4118-b877-59e03b24ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix , response , D, idx):\n",
    "    D_ = D.iloc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de50185-aca2-4ec1-b827-6c4dff82bad5",
   "metadata": {},
   "source": [
    "* This is not quite what is needed as the first argument to `boot_SE()`.\n",
    "* The first two arguments which specify the model will not change in the bootstrap process, and we would like to freeze them.\n",
    "* The function `partial()` from the `functools` module does precisely this: it takes a function as an argument, and freezes some of its arguments, starting from the left.\n",
    "* We use it to freeze the first two model-formula arguments of `boot_OLS()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c031059-bea7-4e05-9710-389e04a10493",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_func = partial(boot_OLS , MS(['horsepower']), 'mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab37a0d0-20ca-4bab-8760-e667dff12bd5",
   "metadata": {},
   "source": [
    "Typing `hp_func?` will show that it has two arguments `D` and `idx` — it is a version of `boot_OLS()` with the first two arguments frozen — and hence is ideal as the first argument for `boot_SE()`. The `hp_func()` function can now be used in order to create bootstrap estimates for the intercept and slope terms by randomly sampling from among the observations with replacement. We first demonstrate its utility on 10 bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5fa89c8-c40a-45a4-ba3c-9502ce59fc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m      hp_func(D, idx)\n",
       "\u001b[31mCall signature:\u001b[39m hp_func(*args, **kwargs)\n",
       "\u001b[31mType:\u001b[39m           partial\n",
       "\u001b[31mString form:\u001b[39m    functools.partial(<function boot_OLS at 0x00000193A5D25EE0>, ModelSpec(terms=['horsepower']), 'mpg')\n",
       "\u001b[31mFile:\u001b[39m           c:\\users\\vijay\\appdata\\local\\programs\\python\\python311\\lib\\functools.py\n",
       "\u001b[31mDocstring:\u001b[39m     \n",
       "partial(func, *args, **keywords) - new function with partial application\n",
       "of the given arguments and keywords."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp_func?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ff5fa08-bb6f-49af-8b90-2bd458944533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.88064456, -0.1567849 ],\n",
       "       [38.73298691, -0.14699495],\n",
       "       [38.31734657, -0.14442683],\n",
       "       [39.91446826, -0.15782234],\n",
       "       [39.43349349, -0.15072702],\n",
       "       [40.36629857, -0.15912217],\n",
       "       [39.62334517, -0.15449117],\n",
       "       [39.0580588 , -0.14952908],\n",
       "       [38.66688437, -0.14521037],\n",
       "       [39.64280792, -0.15555698]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_reset = Auto.reset_index(drop=True)\n",
    "rng = np.random.default_rng(0)\n",
    "np.array([hp_func(Auto_reset,\n",
    "                  rng.choice(392, 392, replace=True)) \n",
    "          for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf4ac3-a127-4b44-8fa3-0db35005f9af",
   "metadata": {},
   "source": [
    "Next, we use the `boot_SE()` function to compute the standard errors of 1,000 bootstrap estimates for the intercept and slope terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4dac455-a5fa-478f-9b25-ef782310b896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     1.270578\n",
       "horsepower    0.005293\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_se = boot_SE(hp_func ,\n",
    "                Auto ,\n",
    "                B=1000,\n",
    "                seed=10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4256d549-b3e8-4133-b21f-0db22cc1b5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model.fit(Auto , Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a124d-78fa-42fd-85e5-43eec99998ae",
   "metadata": {},
   "source": [
    "* The standard error estimates for `ˆβ₀` and `ˆβ₁` obtained using the formulas  are 0.717 for the intercept and 0.006 for the slope.\n",
    "* Interestingly, these are somewhat different from the estimates obtained using the bootstrap.\n",
    "* Does this indicate a problem with the bootstrap?\n",
    "* In fact, it suggests the opposite.\n",
    "* Recall that the standard formulas, rely on certain assumptions.\n",
    "* For example, they depend on the unknown parameter `σ²`, the noise variance.\n",
    "* We then estimate σ² using the RSS.\n",
    "* Now although the formula for the standard errors do not rely on the linear model being correct, the estimate for σ² does.\n",
    "* We see that there is a non-linear relationship in the data, and so the residuals from a linear fit will be inflated, and so will `ˆσ²`.\n",
    "* Secondly, the standard formulas assume (somewhat unrealistically) that the `xi` are fixed, and all the variability comes from the variation in the errors 𝛆ᵢ.\n",
    "* The bootstrap approach does not rely on any of these assumptions, and so it is likely giving a more accurate estimate of the standard errors of `ˆβ₀` and `ˆβ₁` than the results from `sm.OLS`.\n",
    "* Below we compute the bootstrap standard error estimates and the standard linear regression estimates that result from fitting the quadratic model to the data.\n",
    "* Since this model provides a good fit to the data, there is now a better correspondence between the bootstrap estimates and the standard estimates of `SE(ˆβ₀)`, `SE(ˆβ₁)` and `SE(ˆβ₂)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4782745-a0b2-4e13-a8b4-64ea8d41f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14dba1ae-b113-443b-a164-7a629ef20db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chevrolet chevelle malibu</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buick skylark 320</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plymouth satellite</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amc rebel sst</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ford torino</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ford mustang gl</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vw pickup</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dodge rampage</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ford ranger</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chevy s-10</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mpg  cylinders  displacement  horsepower  weight  \\\n",
       "name                                                                           \n",
       "chevrolet chevelle malibu  18.0          8         307.0         130    3504   \n",
       "buick skylark 320          15.0          8         350.0         165    3693   \n",
       "plymouth satellite         18.0          8         318.0         150    3436   \n",
       "amc rebel sst              16.0          8         304.0         150    3433   \n",
       "ford torino                17.0          8         302.0         140    3449   \n",
       "...                         ...        ...           ...         ...     ...   \n",
       "ford mustang gl            27.0          4         140.0          86    2790   \n",
       "vw pickup                  44.0          4          97.0          52    2130   \n",
       "dodge rampage              32.0          4         135.0          84    2295   \n",
       "ford ranger                28.0          4         120.0          79    2625   \n",
       "chevy s-10                 31.0          4         119.0          82    2720   \n",
       "\n",
       "                           acceleration  year  origin  \n",
       "name                                                   \n",
       "chevrolet chevelle malibu          12.0    70       1  \n",
       "buick skylark 320                  11.5    70       1  \n",
       "plymouth satellite                 11.0    70       1  \n",
       "amc rebel sst                      12.0    70       1  \n",
       "ford torino                        10.5    70       1  \n",
       "...                                 ...   ...     ...  \n",
       "ford mustang gl                    15.6    82       1  \n",
       "vw pickup                          24.6    82       2  \n",
       "dodge rampage                      11.6    82       1  \n",
       "ford ranger                        18.6    82       1  \n",
       "chevy s-10                         19.4    82       1  \n",
       "\n",
       "[392 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "393722af-15d3-4510-9ad8-7bb621d04a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  2.067840\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.033019\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000120\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
    "quad_func = partial(boot_OLS ,\n",
    "quad_model ,\n",
    "'mpg')\n",
    "boot_SE(quad_func , Auto , B=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55884011-4c14-4c7c-b4f3-d23d690009f7",
   "metadata": {},
   "source": [
    "We compare the results to the standard errors computed using `sm.OLS()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34903020-b04b-4209-955b-fd49380991a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.800\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sm.OLS(Auto['mpg'],\n",
    "           quad_model.fit_transform(Auto))\n",
    "summarize(M.fit())['std err']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
